{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from imbens.ensemble import SelfPacedEnsembleClassifier as SPEClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "1 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "2  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "3 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "4 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "5 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "1  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "2  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "3  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "4  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "5 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  label  \n",
       "1  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "2  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "3 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "4  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "5 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "\n",
    "path_to_data = '../data/creditcard/creditcard.csv'\n",
    "\n",
    "# col names data set\n",
    "col_names = [\n",
    "    \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"label\"\n",
    "] # V1-V28 are PCA transformed features, but are anonymized due to confidentiality reasons and are not interpretable\n",
    "# Label is 1 if fraud, 0 otherwise\n",
    "\n",
    "# read full data set\n",
    "data = pd.read_csv(path_to_data, names=col_names, index_col=0, header=0)\n",
    "\n",
    "# drop duplicates  & time column\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.drop(\"Time\", axis=1, inplace=True)\n",
    "\n",
    "# Displaying the first 5 rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data sets into X, y respectively\n",
    "X = data.drop(\"label\", axis=1)\n",
    "y = data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvX0lEQVR4nO3deVxV9b7/8TcikBKDJrLTHDM1jTTQo1iJR8Iw8Wq34texblgnbw6laTmdn3OW4b2CHeHYcQhJS7NM6+cQRJlDIhnlLA0nnJiENDYRCsr+/eFh5XbGMILv6/l4fB+61vezvuu7tmx4u/ZaCxdJDgEAABioTnVPAAAAoLoQhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxqpb3RP4o2vSpImKioqqexoAAKASvLy8lJ2dfcU6gtBlNGnSRFlZWdU9DQAAcA2aNm16xTBEELqMijNBTZs25awQAAA1hJeXl7Kysq7qZzdB6CoUFRURhAAAqIW4WBoAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWHWrewImm7MntbqnAPxhvRAQXN1TAGAAzggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYKxKBaEJEyboiy++kN1uV15enlavXq22bds61WzcuFEOh8OpzZ8/36mmWbNmWrt2rYqLi5WXl6fZs2fL1dXVqSYkJETp6ek6efKkvvvuO0VFRV0wn+HDhyszM1MlJSXavn27unbt6tTv4eGhuLg4FRQUqKioSO+9954aN25cmUMGAAC1WKWCUEhIiOLj49W9e3eFhYXJzc1NycnJql+/vlPdggULZLPZrDZu3Lhfd1injtatWyd3d3f16NFDUVFRGjx4sGbMmGHVtGzZUuvWrdPGjRvVuXNnzZ07V4sWLVKfPn2smsjISMXExGj69OkKDAzUrl27lJSUJD8/P6smNjZW/fv31yOPPKKQkBA1adJE77//fqVfJAAAUDu5SHJc68aNGjVSfn6+evbsqS1btkg6e0Zo586dGj169EW3CQ8P19q1a9WkSRMdO3ZMkvTMM88oOjpafn5+Kisr06uvvqp+/fopICDA2m758uXy9fVV3759JUnbt2/Xjh079Nxzz509EBcXHTlyRPPmzVN0dLS8vb2Vn5+vQYMGadWqVZKkdu3aKSMjQ927d1daWtoVj8/Ly0t2u13e3t4qKiq61pfpkubsSa3yMYHa4oWA4OqeAoAaqjI/v3/TNUI+Pj6SpOPHjzutf+yxx5Sfn689e/bolVdeUb169ay+4OBg7dmzxwpBkpSUlCQfHx917NjRqklJSXEaMykpScHBZ78xurm5KSgoyKnG4XAoJSXFqgkKCpK7u7tTzTfffKNDhw5ZNQAAwGx1r3VDFxcXzZ07V1u3btW+ffus9W+//bYOHTqk7Oxs3XnnnYqOjla7du300EMPSZJsNpvy8vKcxqpYttlsl63x8fHRDTfcoAYNGqhu3boXrWnfvr01xqlTp1RYWHhBTcV+zufu7i4PDw9r2cvL66pfDwAAUPNccxCKj4/XHXfcoXvuucdp/cKFC62/7927Vzk5Ofr000/VunVr/fDDD9c+09/BxIkTNW3atOqeBgAA+J1c00dj8+bNU0REhP785z8rKyvrsrUV1+K0adNGkpSbmyt/f3+nmorl3Nzcy9YUFhbq5MmTKigo0OnTpy9ac+4YHh4e1sd3F6s536xZs+Tt7W21pk2bXvbYAABAzVbpIDRv3jw9+OCD6t27tw4ePHjF+s6dO0uScnJyJEmpqakKCAhwursrLCxMhYWF2r9/v1UTGhrqNE5YWJhSU89eXFxWVqb09HSnGhcXF4WGhlo16enpKi0tdapp27atWrRoYdWcr7S0VEVFRU4NAADUXpX6aCw+Pl6DBg3SgAEDVFRUZJ2RqThT07p1aw0aNEjr16/Xjz/+qDvvvFOxsbHatGmT9uzZI0lKTk7W/v37tXTpUo0bN042m00zZ85UfHy8SktLJUmvv/66nn32WUVHR+uNN95Q7969FRkZqX79+llziYmJUWJior788kt98cUXev755+Xp6amEhARJkt1u1+LFixUTE6Pjx4/Lbrdr3rx52rZt21XdMQYAAGq/SgWh4cOHS5I2bdrktH7w4MFKTExUaWmp7rvvPiuUHDlyRKtWrdLMmTOt2vLyckVERGj+/PlKTU1VcXGxEhMTNWXKFKvm4MGD6tevn2JjYzVq1CgdPXpUTz/9tJKTk62alStXys/PTzNmzJDNZtPOnTsVHh7udDfa6NGjVV5erlWrVsnDw0NJSUnWMQAAAPym5wjVdjxHCKg+PEcIwLX63Z4jBAAAUJMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYKxKBaEJEyboiy++kN1uV15enlavXq22bds61Xh4eCguLk4FBQUqKirSe++9p8aNGzvVNGvWTGvXrlVxcbHy8vI0e/Zsubq6OtWEhIQoPT1dJ0+e1HfffaeoqKgL5jN8+HBlZmaqpKRE27dvV9euXSs9FwAAYK5KBaGQkBDFx8ere/fuCgsLk5ubm5KTk1W/fn2rJjY2Vv3799cjjzyikJAQNWnSRO+///6vO6xTR+vWrZO7u7t69OihqKgoDR48WDNmzLBqWrZsqXXr1mnjxo3q3Lmz5s6dq0WLFqlPnz5WTWRkpGJiYjR9+nQFBgZq165dSkpKkp+f31XPBQAAmM1FkuNaN27UqJHy8/PVs2dPbdmyRd7e3srPz9egQYO0atUqSVK7du2UkZGh7t27Ky0tTeHh4Vq7dq2aNGmiY8eOSZKeeeYZRUdHy8/PT2VlZXr11VfVr18/BQQEWPtavny5fH191bdvX0nS9u3btWPHDj333HNnD8TFRUeOHNG8efMUHR19VXO5Ei8vL9ntdnl7e6uoqOhaX6ZLmrMntcrHBGqLFwKCq3sKAGqoyvz8/k3XCPn4+EiSjh8/LkkKCgqSu7u7UlJSrJpvvvlGhw4dUnDw2W9qwcHB2rNnjxWCJCkpKUk+Pj7q2LGjVXPuGBU1FWO4ubkpKCjIqcbhcCglJcWquZq5nM/d3V1eXl5ODQAA1F7XHIRcXFw0d+5cbd26Vfv27ZMk2Ww2nTp1SoWFhU61eXl5stlsVk1eXt4F/RV9l6vx8fHRDTfcoEaNGqlu3boXrTl3jCvN5XwTJ06U3W63WlZW1lW/HgAAoOa55iAUHx+vO+64Q48++mhVzqdazZo1S97e3lZr2rRpdU8JAABcR9cUhObNm6eIiAj9+c9/djprkpubKw8PD+sjswr+/v7Kzc21avz9/S/or+i7XE1hYaFOnjypgoICnT59+qI1545xpbmcr7S0VEVFRU4NAADUXpUOQvPmzdODDz6o3r176+DBg0596enpKi0tVWhoqLWubdu2atGihVJTz14YnJqaqoCAAKe7u8LCwlRYWKj9+/dbNeeOUVFTMUZZWZnS09OdalxcXBQaGmrVXM1cAACA2epWpjg+Pl6DBg3SgAEDVFRUZJ2RqThTY7fbtXjxYsXExOj48eOy2+2aN2+etm3bZt2llZycrP3792vp0qUaN26cbDabZs6cqfj4eJWWlkqSXn/9dT377LOKjo7WG2+8od69eysyMlL9+vWz5hITE6PExER9+eWX+uKLL/T888/L09NTCQkJknRVcwEAAGarVBAaPny4JGnTpk1O6wcPHqzExERJ0ujRo1VeXq5Vq1bJw8NDSUlJ1naSVF5eroiICM2fP1+pqakqLi5WYmKipkyZYtUcPHhQ/fr1U2xsrEaNGqWjR4/q6aefVnJyslWzcuVK+fn5acaMGbLZbNq5c6fCw8Od7ka70lwAAIDZftNzhGo7niMEVB+eIwTgWv1uzxECAACoyQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgrEoHoXvvvVcffvihsrKy5HA4NGDAAKf+hIQEORwOp7ZhwwanmgYNGmjZsmUqLCzUiRMntGjRInl6ejrVBAQEaPPmzSopKdHhw4c1duzYC+by8MMP68CBAyopKdHu3bvVt2/fC2qmT5+u7Oxs/fLLL/r444/Vpk2byh4yAACopSodhDw9PbVr1y6NGDHikjUbNmyQzWaz2l/+8hen/rfeeksdO3ZUWFiYIiIi1LNnTy1YsMDq9/LyUnJysg4dOqSgoCCNHTtW06ZN05AhQ6ya4OBgLV++XIsXL9Zdd92lNWvWaM2aNerYsaNVM27cOI0cOVJDhw5Vt27dVFxcrKSkJHl4eFT2sAEAQC3kIslxrRs7HA4NHDhQH3zwgbUuISFBvr6+evDBBy+6Tfv27XXgwAF16dJF6enpkqT7779f69ev1y233KKcnBwNHTpUL7/8smw2m8rKyiRJs2bN0sCBA3X77bdLklasWCFPT0/179/fGjs1NVU7d+7UsGHDJEnZ2dmaM2eO5syZI0ny9vZWXl6eBg8erHfeeeeKx+fl5SW73S5vb28VFRVdwyt0eXP2pFb5mEBt8UJAcHVPAUANVZmf39flGqFevXopLy9PGRkZ+sc//qGGDRtafcHBwTpx4oQVgiQpJSVF5eXl6tatm1WzefNmKwRJUlJSktq3by9fX1+rJiUlxWm/SUlJCg4++82zVatWuvnmm51q7Ha70tLSrJrzubu7y8vLy6kBAIDaq8qD0EcffaQnnnhCoaGhGj9+vEJCQrRhwwbVqXN2VzabTceOHXPa5syZMzp+/LhsNptVk5eX51RTsXylmnP7z93uYjXnmzhxoux2u9WysrIqffwAAKDmqFvVA577kdPevXu1e/du/fDDD+rVq5c+/fTTqt5dlZo1a5ZiYmKsZS8vL8LQH8jJ4mJ9FLdAez/ZrKLjx9W0fVsNnDBaze/oIEkqKjiutbHx+jb1C5UUFal1UGc9OPEF+bVodtlxNy9doW0rV+tETq48fX3VKezPeuD5YXL797Vk2955X9veeV/Hs3MkSbZbWyts6FO6/d5fzyx+MPs17fhgndzr1VO/54crKOJ+q29X0if68v9t0F/j/reqXxIAwG9U5UHofJmZmcrPz1ebNm306aefKjc3V40bN3aqcXV1VcOGDZWbmytJys3Nlb+/v1NNxfKVas7tP39dxfLOnTsvOtfS0lKVlpZe45Hiels5dZZyv/9Bf3llinwaN1L62iT9c8hIjVvztrwb+ylh1Hi51q2rJ/8erRs8PbXpzeX655CRGrvmbXnUr3fRMb9al6R1c+fr/8z4m1p2vlP5hw5rxaSZkouLBowbJUny8fdTv+eHq1GLZpLDoR0frlfCyHEa826ibG1aa99nW/T1+mQ9s+A15R86onemvKx2d3fTjQ18VVL0s9bP+6eGLvz77/lSAQCu0nV/jlDTpk110003KSfn7P+mU1NT1aBBAwUGBlo1vXv3Vp06dZSWlmbV9OzZU3Xr/prTwsLClJGRoZ9++smqCQ0NddpXWFiYUlPPXoCcmZmpnJwcpxovLy9169bNqkHNUXbypPakfKaIMSN0a5e71Kh5M90//Gk1anaLtr2zWgWHjujQ7r16aPJYNb+jgxq3aqGHJo9T2alT+nrDx5cc9+DOPWp5V4AC+92vhk1vVrse3XRX3zAd3rvfqunY617d3rOH/Fo0k1/L5npg5FC516+nQ7v3SpLyfjikW7sGqlnH2xX4QB/d4Omp41nZkqS1MXHqEfmgGtx88Y9jAQDV65pun+/UqZM6deok6exFyZ06dVKzZs3k6emp2bNnq1u3bmrRooV69+6tDz74QN9//72SkpIkSRkZGdqwYYMWLlyorl27qkePHoqLi9OKFSussPT222+rtLRUixcvVocOHRQZGalRo0Y5fWz12muvKTw8XGPGjFG7du00depUdenSRXFxcVbN3LlzNWnSJPXv31933HGH3nzzTWVnZ2vNmjW/5TVDNThz5ozKz5xRXXd3p/V1b/BQ5te7dPrfZ/LqevzaX6dOHbm6uSnzq12XHLdl5wAd3f+NDu/ZJ0n68UiWDmzZ5vSx17nKz5zR1xs+VmnJSbXoFCBJatKujY7sO6BfCu06si9DZadOqVGzW/TDV7uUdeBb3ftY5G86dgDA9VPpj8a6dOmizz77zFqOjY2VJC1ZskTDhg3TnXfeqaioKPn6+io7O1vJycmaPHmy00dOjz32mOLi4vTJJ5+ovLxcq1at0siRI61+u92uPn36KD4+Xunp6SooKNCMGTO0cOFCqyY1NVWDBg3SzJkz9corr+i7777TwIEDtW/fPqtm9uzZ8vT01IIFC+Tr66utW7cqPDxcp06dquxho5rd4OmpFp3uUMo/E+TfuqW8bmqor9d/rEO79qpR81vUuFVLNbjZpvVz5+vhKePlXr+eNr+5QoV5x2Qv+PGS4wb2u1/FPxUq7omhcsih8tNnFBz5oO4bMtipLufb7/X3x/9bp0tL5V6/np6c+6pst7aSJLW/u7uCIsI19y9Pyc3DQ395ebLc69fTqpdm69GZk7Xtnfe1dfl78vT10SNTJ8jWpvX1fKkAAJXwm54jVNvxHKE/loIjR/XO5Jf1Q/pO1XF1VdPb28qvRXMd3Z+h8R+u0JF9GVo59RVlf/Od6ri66rbuXeTiUkdyODTk9diLjvn9jq+0bOxkhT/3jFoEdFDBkaNa8+pcdX/oPxQ29Cmr7nRZmX7KyVVJUbF2f/yp0t7/fxqe8A8rDJ0vaf5inbQXqevACC14ZpRefH+Z9m/6XJ8vf0+jVy65Hi9PrcNzhABcq8r8/L7uF0sDVaVRs1s0Ysl8nfqlRKeKi+Xt10hvvjhJN93SVJLUrGN7vfDemyop+llnysp0Y8MGem3QX3VLh/aXHPOjuAUK6h+u7g/9hyTp5rZtVPrLSb0741WF/vdg67EPdd3c1Kh5M2s/R/Ye0JZl7+iRqRMuGDPvh4P6au1HGvNuor5YvVatgzrrxoYN1On+UL0z5WWdLC7WDef9ShkAQPXgl66ixvGoX0/efo30S6Fd32xLU8c/3+vUX8/rRt3YsIHyDx3RkX0ZuqN3z0uOVVZy8uxZo3O4uP572XHpk6UOh0OnS8suuv69GdH6j7Ej5VG/vsrPnNGZ06clSeX//tNxpvyqjhMAcP1xRgg1Rsbn2yWHQ34tW6jg8FGtjYlT41Yt9KeBEZLOPq/Hs2EDNbD5K+e7f2lNdKzu6N1T7Xp0s8Z4+2/T5dP47O3wktSh1z3a9OZyNb29rZoHdFTB4aP6KG6BOoTcozqurpKkdXP/ofb3BKvBzTadKi7WV+uT9a8dX2nI63MvmGPaqg91Y8MG6tjrbDhrddedSp6/WId27dWBranyv7WV6nnzxHIA+KMgCKHGOFn0s9a/9rp+yjum+j7euvO+Xuo7cqhc3c5+GdsLftQH//N3/fzjcXn7NVJQ/3Cn63wk6aecPKczQPf992DJxUUb5v1ThcfydWODBuoQcrceGDnUqvn5+Akt/78zZM//UfW8btTNt92qIa/PVbsef3Iau6jguFIWLtFzS3/9BcLNAzoq5Im/aNGIF3Rjwwb6y8uTr8MrAwC4VlwsfRlcLA1UHy6WBnCtqv2XrgIAANQEBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGqnQQuvfee/Xhhx8qKytLDodDAwYMuKBm+vTpys7O1i+//KKPP/5Ybdq0cepv0KCBli1bpsLCQp04cUKLFi2Sp6enU01AQIA2b96skpISHT58WGPHjr1gPw8//LAOHDigkpIS7d69W3379q30XAAAgLkqHYQ8PT21a9cujRgx4qL948aN08iRIzV06FB169ZNxcXFSkpKkoeHh1Xz1ltvqWPHjgoLC1NERIR69uypBQsWWP1eXl5KTk7WoUOHFBQUpLFjx2ratGkaMmSIVRMcHKzly5dr8eLFuuuuu7RmzRqtWbNGHTt2rNRcAACAuVwkOa51Y4fDoYEDB+qDDz6w1mVnZ2vOnDmaM2eOJMnb21t5eXkaPHiw3nnnHbVv314HDhxQly5dlJ6eLkm6//77tX79et1yyy3KycnR0KFD9fLLL8tms6msrEySNGvWLA0cOFC33367JGnFihXy9PRU//79rX2npqZq586dGjZs2FXN5Uq8vLxkt9vl7e2toqKia32ZLmnOntQqHxOoLV4ICK7uKQCooSrz87tKrxFq1aqVbr75ZqWkpFjr7Ha70tLSFBx89ptacHCwTpw4YYUgSUpJSVF5ebm6detm1WzevNkKQZKUlJSk9u3by9fX16o5dz8VNRX7uZq5nM/d3V1eXl5ODQAA1F5VGoRsNpskKS8vz2l9Xl6e1Wez2XTs2DGn/jNnzuj48eNONRcb49x9XKrm3P4rzeV8EydOlN1ut1pWVtZVHDUAAKipuGvsHLNmzZK3t7fVmjZtWt1TAgAA11GVBqHc3FxJkr+/v9N6f39/qy83N1eNGzd26nd1dVXDhg2dai42xrn7uFTNuf1Xmsv5SktLVVRU5NQAAEDtVaVBKDMzUzk5OQoNDbXWeXl5qVu3bkpNPXthcGpqqho0aKDAwECrpnfv3qpTp47S0tKsmp49e6pu3bpWTVhYmDIyMvTTTz9ZNefup6KmYj9XMxcAAGC2a7p9vlOnTurUqZOksxcld+rUSc2aNZMkzZ07V5MmTVL//v11xx136M0331R2drbWrFkjScrIyNCGDRu0cOFCde3aVT169FBcXJxWrFihnJwcSdLbb7+t0tJSLV68WB06dFBkZKRGjRqlmJgYax6vvfaawsPDNWbMGLVr105Tp05Vly5dFBcXZ9VcaS4AAMBsda9c4qxLly767LPPrOXY2FhJ0pIlS/Tkk09q9uzZ8vT01IIFC+Tr66utW7cqPDxcp06dsrZ57LHHFBcXp08++UTl5eVatWqVRo4cafXb7Xb16dNH8fHxSk9PV0FBgWbMmKGFCxdaNampqRo0aJBmzpypV155Rd99950GDhyoffv2WTVXMxcAAGCu3/QcodqO5wgB1YfnCAG4VtX2HCEAAICahCAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGqvIgNHXqVDkcDqd24MABq9/Dw0NxcXEqKChQUVGR3nvvPTVu3NhpjGbNmmnt2rUqLi5WXl6eZs+eLVdXV6eakJAQpaen6+TJk/ruu+8UFRV1wVyGDx+uzMxMlZSUaPv27eratWtVHy4AAKjBrssZob1798pms1ntnnvusfpiY2PVv39/PfLIIwoJCVGTJk30/vvv/zqhOnW0bt06ubu7q0ePHoqKitLgwYM1Y8YMq6Zly5Zat26dNm7cqM6dO2vu3LlatGiR+vTpY9VERkYqJiZG06dPV2BgoHbt2qWkpCT5+fldj0MGAAA1kIskR1UOOHXqVA0cOFB33XXXBX3e3t7Kz8/XoEGDtGrVKklSu3btlJGRoe7duystLU3h4eFau3atmjRpomPHjkmSnnnmGUVHR8vPz09lZWV69dVX1a9fPwUEBFhjL1++XL6+vurbt68kafv27dqxY4eee+65swfq4qIjR45o3rx5io6Ovqpj8fLykt1ul7e3t4qKin7T63Ixc/akVvmYQG3xQkBwdU8BQA1VmZ/f1+WM0G233aasrCz961//0rJly9SsWTNJUlBQkNzd3ZWSkmLVfvPNNzp06JCCg89+0wsODtaePXusECRJSUlJ8vHxUceOHa2ac8eoqKkYw83NTUFBQU41DodDKSkpVs3FuLu7y8vLy6kBAIDaq8qDUFpamgYPHqzw8HANGzZMrVq10pYtW3TjjTfKZrPp1KlTKiwsdNomLy9PNptNkmSz2ZSXl3dBf0Xf5Wp8fHx0ww03qFGjRqpbt+5FayrGuJiJEyfKbrdbLSsr69peBAAAUCPUreoBP/roI+vve/bsUVpamg4dOqTIyEiVlJRU9e6q1KxZsxQTE2Mte3l5EYYAAKjFrvvt84WFhfr222/Vpk0b5ebmysPDQz4+Pk41/v7+ys3NlSTl5ubK39//gv6KvsvVFBYW6uTJkyooKNDp06cvWlMxxsWUlpaqqKjIqQEAgNrrugchT09P3XrrrcrJyVF6erpKS0sVGhpq9bdt21YtWrRQaurZC4dTU1MVEBDgdHdXWFiYCgsLtX//fqvm3DEqairGKCsrU3p6ulONi4uLQkNDrRoAAIAqD0L/8z//o549e6pFixYKDg7W6tWrdebMGS1fvlx2u12LFy9WTEyMevXqpcDAQCUkJGjbtm1KS0uTJCUnJ2v//v1aunSp7rzzTvXp00czZ85UfHy8SktLJUmvv/66WrdurejoaLVr107Dhg1TZGSkYmNjrXnExMRoyJAheuKJJ9S+fXvNnz9fnp6eSkhIqOpDBgAANVSVXyN0yy23aPny5brpppuUn5+vrVu3qnv37iooKJAkjR49WuXl5Vq1apU8PDyUlJSk4cOHW9uXl5crIiJC8+fPV2pqqoqLi5WYmKgpU6ZYNQcPHlS/fv0UGxurUaNG6ejRo3r66aeVnJxs1axcuVJ+fn6aMWOGbDabdu7cqfDwcKe70QAAgNmq/DlCtQnPEQKqD88RAnCtqv05QgAAADUBQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAH94w4cPV2ZmpkpKSrR9+3Z17dr1krUdOnTQe++9p8zMTDkcDo0aNeqCmoq+81tcXJxVM2fOHP344486fPiwBg0a5LT9ww8/rA8//LDqDhDVhiAEAPhDi4yMVExMjKZPn67AwEDt2rVLSUlJ8vPzu2h9/fr19cMPP2jChAnKycm5aE3Xrl1ls9msdt9990mS3n33XUlSRESEBg0apD59+mjcuHFatGiRbrrpJkmSt7e3Xn75ZY0YMeI6HC1+bwQhAMAf2pgxY7Rw4UItWbJEBw4c0NChQ/XLL7/oqaeeumj9l19+qXHjxumdd97RqVOnLlpTUFCgvLw8q0VEROj777/Xpk2bJEm33367PvvsM6Wnp2vFihWy2+1q1aqVJGn27NmaP3++jhw5cn0OGL8rghAA4A/Lzc1NQUFBSklJsdY5HA6lpKQoODi4yvbx+OOP64033rDW7dq1S126dJGvr68CAwNVr149ff/997r77rsVGBiov//971Wyb1Q/ghAA4A+rUaNGqlu3rvLy8pzW5+XlyWazVck+Bg4cKF9fXy1ZssRal5ycrGXLlmnHjh1asmSJoqKiVFxcrPnz52vo0KEaNmyYMjIytHXrVnXo0KFK5oHqUbe6JwAAQHX661//qg0bNlxwPdH06dM1ffp0a3nKlClKSUlRWVmZJk2apICAAEVEROjNN99Uly5dfu9po4oYcUaoMncbAAD+OAoKCnT69Gn5+/s7rff391dubu5vHr958+a67777tGjRosvWtWvXTo8//rgmT56sXr16afPmzSooKNDKlSsVFBSkG2+88TfPBdWj1gehyt5tAAD44ygrK1N6erpCQ0OtdS4uLgoNDVVqaupvHv/JJ5/UsWPHtG7dusvW/fOf/9SYMWNUXFwsV1dXubm5SZL1p6ur62+eC6pHrQ9Clb3bAADwxxITE6MhQ4boiSeeUPv27TV//nx5enoqISFBkpSYmKhXXnnFqndzc1OnTp3UqVMnubu7q2nTpurUqZNuvfVWp3FdXFz05JNPKjExUWfOnLnk/p9++mnl5+dr7dq1kqTPP/9cvXv3Vrdu3TR69Gjt27dPhYWF1+HI8Xuo1dcIVdxtMGvWLGvd5e42cHd3l4eHh7Xs5eXl9GdVc6/D/yCAS7le7zvUPBs2bNCkSZP00ksvyd/fX3v27NFDDz2kkpISeXl5qVWrVnJ1dbW+Zpo3b66dO3da248dO1Zjx47Vli1b1K9fP2t979691aJFC61cufKSX29+fn6aNGmSwsLCrJqMjAzFxcVp/fr1ys/P19ChQ/l6/YOpzL+HiyTH9ZtK9br55puVnZ2t4OBgbd++3VofHR2tkJAQde/e3al+6tSpmjZt2u88SwAAcD00bdpU2dnZl62p1WeEKmvWrFmKiYlxWtewYUMdP368mmaE34uXl5eysrLUtGlTFRUVVfd0AFwnvNfN4eXldcUQJNXyIFTZuw1KS0tVWlrqtI43ilmKior4NwcMwHu99rvaf99afbH09b7bAAAA1Gy1+oyQdPZug8TERH355Zf64osv9PzzzzvdbQAAAMxV64PQypUr5efnpxkzZshms2nnzp0KDw/XsWPHqntq+AM5deqUpk2bdslf0AigduC9jvPV6rvGAAAALqdWXyMEAABwOQQhAABgLIIQAAAwFkEIuI5CQkLkcDjk4+NT3VMBUAUSEhK0evXq6p4GqhBBCDVGQkKCHA6Hxo8f77R+wIABcji45h+ozSre/+e383+RKlBZBCHUKCUlJRo/frx8fX2rbEw3N7cqGwvA9bNhwwbZbDanlpmZ6VTD+xmVRRBCjZKSkqLc3FxNnDjxkjX/+Z//qb179+rkyZPKzMzUmDFjnPozMzM1adIkJSYmqrCwUAsWLFBUVJROnDihfv36KSMjQ8XFxXr33XdVr149PfHEE8rMzNTx48f12muvqU6dX982jz/+uHbs2CG73a6cnBy99dZb8vPzu27HD5js1KlTysvLc2qffPKJ5s2bp9jYWOXn5yspKUmSNHr0aO3evVs///yzDh8+rPj4eHl6elpjTZ06VV9//bXT+KNGjXIKVnXq1NGcOXN04sQJFRQUKDo6Wi4uLr/PweJ3QxBCjXLmzBn97W9/03PPPaemTZte0B8YGKiVK1dqxYoVCggI0LRp0/TSSy8pKirKqe7FF1/Url27dNddd+mll16SJNWvX18jR47Uo48+qvDwcPXq1UurV6/WAw88oAceeED/9V//pWeeeUYPP/ywNY6bm5smT56sTp06aeDAgWrZsqWWLFlyXV8DAM6ioqJUWlqqu+++W0OHDpUklZeXa+TIkerYsaOioqLUu3dvzZ49u1LjvvDCCxo8eLCeeuop3XPPPWrYsKEefPDB63EIqGYOGq0mtISEBMfq1asdkhzbtm1zLFq0yCHJMWDAAIfj7EVCjmXLljmSkpKctouOjnbs3bvXWs7MzHS8//77TjVRUVEOh8PhaN26tbVu/vz5jp9//tnh6elprduwYYNj/vz5l5xjUFCQw+FwWNuEhIQ4HA6Hw8fHp9pfPxqtJreEhARHWVmZo6ioyGorV650bNy40ZGenn7F7R966CFHfn6+tTx16lTH119/7VQzatQoR2ZmprWclZXlePHFF61lV1dXx+HDh63vQ7Ta0TgjhBpp/PjxioqKUvv27Z3W33777fr888+d1n3++ee67bbbnD7S+vLLLy8Ys7i4WD/88IO1nJeXp4MHD6q4uNhpXePGja3lwMBAffjhhzp06JDsdrs2bdokSWrevPlvO0AAF9i4caM6d+5stZEjR0qS0tPTL6gNDQ1VSkqKjh49KrvdrqVLl6pRo0aqV6/eVe3L29tbTZo0UVpamrXuzJkzF/3egZqNIIQaacuWLUpKStKsWbOuaftzw02FsrIyp2WHw3HRdRWBqn79+kpKSpLdbtdjjz2mrl27WqfN3d3dr2leAC6tuLhY//rXv6yWm5trrT9XixYttHbtWu3evVsPPfSQgoKCNGLECEm/vjfLy8svuN6HC63NVOt/6SpqrwkTJmjnzp365ptvrHUHDhzQ3Xff7VR3991369tvv1V5eXmV7r99+/Zq1KiRJkyYoKNHj0qSunTpUqX7AFB5QUFBqlOnjl544QXr0RqRkZFONfn5+bLZbE7rOnfubP3dbrcrOztb3bp105YtWyRJrq6uCgoK0ldffXV9DwC/K84Iocbau3ev3nrrLev0uCTNmTNHoaGhmjRpkm677TY98cQTevbZZ/W///u/Vb7/w4cP69SpU3ruuefUqlUr9e/fX5MnT67y/QConO+//17u7u7We/Pxxx+3LqKu8Nlnn8nPz0/jxo1T69atNXz4cPXt29ep5rXXXtOECRM0YMAAtWvXTv/4xz+q9NEd+GMgCKFGmzJlitO1P19//bUiIyP16KOPau/evZoxY4amTJmixMTEKt93QUGBBg8erEceeUT79+/XhAkT9OKLL1b5fgBUzu7duzV69GiNHz9ee/fu1WOPPXbBIzcyMjI0fPhwjRgxQrt27dKf/vSnC/7DNGfOHC1dulSJiYlKTU1VUVERT5WuhVx09qppAAAA43BGCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABj/X9S2KmSytqpGgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    283253\n",
       "1       473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize class imbalance\n",
    "plt.bar([\"Normal\", \"Fraud\"], data[\"label\"].value_counts())\n",
    "total = len(data)\n",
    "fraud_percentage = (data[\"label\"].value_counts()[1] / total) * 100\n",
    "normal_percentage = (data[\"label\"].value_counts()[0] / total) * 100\n",
    "\n",
    "plt.text(0, data[\"label\"].value_counts()[0] / 2, f'{normal_percentage:.2f}%', ha='center', color='black')\n",
    "plt.text(1, data[\"label\"].value_counts()[1] / 2, f'{fraud_percentage:.2f}%', ha='center', color='white')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Partition Dataset:\n",
    "We stratify the split to ensure that the class distribution is preserved in the partitions.\n",
    "\"\"\"\n",
    "\n",
    "# First 80/20 split on original data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Then 50/50 split on test data for validation and test set.\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV for XGBoost...\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Best parameters from RandomizedSearchCV: {'xgb__tree_method': 'hist', 'xgb__subsample': 0.4, 'xgb__scale_pos_weight': 580, 'xgb__reg_lambda': 0.3, 'xgb__reg_alpha': 0.9, 'xgb__objective': 'binary:logistic', 'xgb__n_estimators': 700, 'xgb__max_leaves': 256, 'xgb__max_depth': 20, 'xgb__learning_rate': 0.1, 'xgb__gamma': 0.3, 'xgb__eval_metric': 'auc', 'xgb__colsample_bytree': 1, 'xgb__booster': 'gbtree'}\n",
      "-----------------------------------------------------\n",
      "\n",
      "Evaluating Vanilla XGBoost...\n",
      "Precision scores: [nan nan nan nan nan nan nan nan nan nan]\n",
      "Recall scores: [0.72972973 0.78378378 0.73684211 0.78947368 0.81578947 0.84210526\n",
      " 0.89473684 0.71052632 0.86842105 0.86842105]\n",
      "F1 scores: [0.81818182 0.85294118 0.82352941 0.84507042 0.88571429 0.91428571\n",
      " 0.91891892 0.81818182 0.91666667 0.90410959]\n",
      "\n",
      "Cross-Validation Results for Vanilla XGBoost:\n",
      "Precision: nan Â± nan\n",
      "Recall: 0.8040 Â± 0.0612\n",
      "F1-Score: 0.8698 Â± 0.0405\n",
      "\n",
      "Test Set Classification Report for Vanilla XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28326\n",
      "           1       0.97      0.77      0.86        47\n",
      "\n",
      "    accuracy                           1.00     28373\n",
      "   macro avg       0.99      0.88      0.93     28373\n",
      "weighted avg       1.00      1.00      1.00     28373\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "Evaluating RandomizedSearchCV XGBoost...\n",
      "Precision scores: [nan nan nan nan nan nan nan nan nan nan]\n",
      "Recall scores: [0.75675676 0.78378378 0.78947368 0.84210526 0.84210526 0.84210526\n",
      " 0.86842105 0.76315789 0.86842105 0.84210526]\n",
      "F1 scores: [0.8115942  0.84057971 0.84507042 0.85333333 0.87671233 0.90140845\n",
      " 0.90410959 0.84057971 0.86842105 0.88888889]\n",
      "\n",
      "Cross-Validation Results for RandomizedSearchCV XGBoost:\n",
      "Precision: nan Â± nan\n",
      "Recall: 0.8198 Â± 0.0401\n",
      "F1-Score: 0.8631 Â± 0.0285\n",
      "\n",
      "Test Set Classification Report for RandomizedSearchCV XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28326\n",
      "           1       0.95      0.79      0.86        47\n",
      "\n",
      "    accuracy                           1.00     28373\n",
      "   macro avg       0.97      0.89      0.93     28373\n",
      "weighted avg       1.00      1.00      1.00     28373\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "Evaluating SPE-Boosted XGBoost...\n",
      "Precision scores: [nan nan nan nan nan nan nan nan nan nan]\n",
      "Recall scores: [0.81081081 0.81081081 0.78947368 0.84210526 0.86842105 0.86842105\n",
      " 0.89473684 0.76315789 0.89473684 0.84210526]\n",
      "F1 scores: [0.82857143 0.84057971 0.84507042 0.85333333 0.91891892 0.86486486\n",
      " 0.87179487 0.82857143 0.90666667 0.89189189]\n",
      "\n",
      "Cross-Validation Results for SPE-Boosted XGBoost:\n",
      "Precision: nan Â± nan\n",
      "Recall: 0.8385 Â± 0.0421\n",
      "F1-Score: 0.8650 Â± 0.0303\n",
      "\n",
      "Test Set Classification Report for SPE-Boosted XGBoost:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28326\n",
      "           1       0.93      0.79      0.85        47\n",
      "\n",
      "    accuracy                           1.00     28373\n",
      "   macro avg       0.96      0.89      0.93     28373\n",
      "weighted avg       1.00      1.00      1.00     28373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random search parameter space, prefix parameters with 'xgb__'\n",
    "search_space_random_tuned = {\n",
    "    'xgb__objective': ['binary:logistic'],\n",
    "    'xgb__max_leaves': [0, 2**6, 2**8],\n",
    "    'xgb__learning_rate': [0.002, 0.1, 0.3],\n",
    "    'xgb__gamma': [0.1, 0.3],\n",
    "    'xgb__max_depth': [6, 12, 20, 25],\n",
    "    'xgb__subsample': [0.4, 0.7, 1],\n",
    "    'xgb__colsample_bytree': [0.4, 0.5, 0.7, 1],\n",
    "    'xgb__reg_alpha': [0, 0.9, 1],\n",
    "    'xgb__reg_lambda': [0.3, 1],\n",
    "    'xgb__scale_pos_weight': [1, 2, 4, 580],\n",
    "    'xgb__eval_metric': ['auc'],\n",
    "    'xgb__n_estimators': [100, 170, 500, 700, 1000, 2000, 5000],\n",
    "    'xgb__booster': ['gbtree'],\n",
    "    'xgb__tree_method': ['hist'],\n",
    "}\n",
    "\n",
    "# Vanilla XGBoost\n",
    "vanilla_xgb_pipeline = Pipeline([\n",
    "    ('xgb', XGBClassifier())  # Default XGBoost classifier\n",
    "])\n",
    "\n",
    "# RandomizedSearchCV XGBoost\n",
    "random_search_xgb = Pipeline([\n",
    "    ('xgb', XGBClassifier())\n",
    "])\n",
    "\n",
    "# 10-fold cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=random_search_xgb,\n",
    "    param_distributions=search_space_random_tuned,\n",
    "    n_iter=10,\n",
    "    scoring='f1',  # Use F1-score to handle imbalanced classes\n",
    "    cv=cv, # 10-fold stratified cross-validation\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Run random search on XGBoost and fit to training data\n",
    "print(\"Running RandomizedSearchCV for XGBoost...\")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from random search\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters from RandomizedSearchCV: {best_params}\")\n",
    "\n",
    "# Best estimator from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "\n",
    "spe_boosted_xgb_pipeline = Pipeline([\n",
    "    ('spe_xgb', SPEClassifier())  # Self-paced ensemble classifier with XGBoost as base learner\n",
    "])\n",
    "\n",
    "models = [\n",
    "    ('Vanilla XGBoost', vanilla_xgb_pipeline),\n",
    "    ('RandomizedSearchCV XGBoost', best_xgb_model),\n",
    "    ('SPE-Boosted XGBoost', spe_boosted_xgb_pipeline)\n",
    "]\n",
    "\n",
    "# Define custom scoring methods\n",
    "scoring_metrics = {\n",
    "    'precision': make_scorer(precision_score, average='binahowry'),\n",
    "    'recall': make_scorer(recall_score, average='binary'),\n",
    "    'f1': make_scorer(f1_score, average='binary')\n",
    "}\n",
    "\n",
    "# Evaluation loop\n",
    "for model_name, model in models:\n",
    "    print('-----------------------------------------------------')\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "\n",
    "    # Perform cross-validation for each scoring metric\n",
    "    precision_scores = cross_val_score(model, X_train, y_train, cv=10, scoring=scoring_metrics['precision'])\n",
    "    print(f\"Precision scores: {precision_scores}\")\n",
    "    recall_scores = cross_val_score(model, X_train, y_train, cv=10, scoring=scoring_metrics['recall'])\n",
    "    print(f\"Recall scores: {recall_scores}\")\n",
    "    f1_scores = cross_val_score(model, X_train, y_train, cv=10, scoring=scoring_metrics['f1'])\n",
    "    print(f\"F1 scores: {f1_scores}\")\n",
    "\n",
    "    # Calculate mean and standard deviation for each metric\n",
    "    precision_mean, precision_std = np.mean(precision_scores), np.std(precision_scores)\n",
    "    recall_mean, recall_std = np.mean(recall_scores), np.std(recall_scores)\n",
    "    f1_mean, f1_std = np.mean(f1_scores), np.std(f1_scores)\n",
    "\n",
    "    # Print cross-validation results\n",
    "    print(f\"\\nCross-Validation Results for {model_name}:\")\n",
    "    print(f\"Precision: {precision_mean:.4f} Â± {precision_std:.4f}\")\n",
    "    print(f\"Recall: {recall_mean:.4f} Â± {recall_std:.4f}\")\n",
    "    print(f\"F1-Score: {f1_mean:.4f} Â± {f1_std:.4f}\")\n",
    "\n",
    "    # Fit the model on the full training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Test set evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nTest Set Classification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
